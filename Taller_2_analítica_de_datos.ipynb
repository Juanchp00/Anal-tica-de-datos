{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taller 2 analítica de datos ",
      "provenance": [],
      "authorship_tag": "ABX9TyPdeGF88va9OGG87pYZBgb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juanchp00/Anal-tica-de-datos/blob/main/Taller_2_anal%C3%ADtica_de_datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rxMcu0E_2_Y"
      },
      "source": [
        "#Taller 2\n",
        "\n",
        "**Juan José Chamorro Paz**\n",
        "\n",
        "**817513**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KPpDEY2AEWN"
      },
      "source": [
        "##Consulta \n",
        "1. Consultar modelo, función de costo y estrategia de optimización de los \n",
        "siguientes clasificadores:\n",
        "\n",
        "  * Naive Bayes\n",
        "  * Linear discriminant analysis\n",
        "  * SGD classifier\n",
        "  * Linear SVC\n",
        "  * SVC con kernel rbf\n",
        "  * Random Forest\n",
        "  * K neighbors classifier\n",
        "  * Logistic Regression (es un clasificador no regresor)\n",
        "\n",
        "\n",
        "2. A partir de la base de datos trabajada en el cuaderno \n",
        "https://github.com/amalvarezme/AnaliticaDatos/blob/master/3_DeteccionClasificacionGH/pruebapeopleclasificacion.ipynb , realizar un análisis comparativo en términos de acierto, classification report, ROC, y AUC de los métodos del punto 1. Utilizar validación cruzada según el cuaderno referido. Discuta los resultados obtenidos y pruebe distintos pipelines que incluyan normalización standard scaler, min max, y sin normalización.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbJTzzoXBNTO"
      },
      "source": [
        "###Punto 1\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzKZ-AX8assw"
      },
      "source": [
        "####Naive Bayes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSchHD1jBTsA"
      },
      "source": [
        "se basa en la suposición “ingenua” de Bayes la cual asume independencia condicional entre cada par de características dado el valor de la variable de clase.\n",
        "El teorema de Bayes establece que \n",
        "\n",
        "$$P(y | x_1, ..., x_n)=\\frac{P(y)P(x_1, ..., x_n|y)}{P(x_1, ..., x_n)} $$\n",
        "\n",
        "asumiendo \"ingenuamente\" la independencia condicional: \n",
        "\n",
        "$$P(x_i|y,x_1,...,x_{i-1},x_{i+1},...,x_n)=P(x_i|y)$$\n",
        "\n",
        "para todos $i$, por lo que \n",
        "\n",
        "$$P(y | x_1, ..., x_n)=\\frac{P(y)\\prod_{i=1}^n P(x_i|y)}{P(x_1, ..., x_n)} $$\n",
        "\n",
        "Con $P(x_1,...,x_n)$ constante dada la entrada, se puede obtener la siguiente regla de clasificación\n",
        "\n",
        "$$\\hat y = arg max_y P(y)\\prod_{i=1}^n P(x_i|y)$$\n",
        "\n",
        "Usando la aproximación máxima (MAP) para encontrar $P(y)$ y $P(x_i|y)$.\n",
        "Esta clasificación requiere una pequeña cantidad de datos de entrenamiento para estimar los parámetros necesarios, además, suelen ser mucho más rapidos que clasificadores más sofisticados, y cada distribución se puede estimar de forma independiente como una distribución unidimensional debido a el desacoplamiento de las distribuciones de características condicionales de clase, sin embargo, el clasificador \"Naive Bayes\" se cnsidera como un mal estimador, por lo que sus predicciones no son muy tomadas encuenta.\n",
        "\n",
        "Uno de los clasificadores de \"Naive Bayes\" es el Gaussiano el cual implementa una probabilidad Gaussiana para su clasificación.\n",
        "\n",
        "$$P(x_i|y)=\\frac{1}{\\sqrt{2\\pi \\sigma_{y}^2}} exp(-\\frac{(x_i-\\mu_y)^2}{2\\sigma_y^2})$$\n",
        "\n",
        "Los parametros $\\sigma_y$ y $\\mu_y$ se estiman utilizando la máxima verosimilitud.\n",
        "\n",
        "**Código de importación**\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLBjCi_-avEz"
      },
      "source": [
        "####Linear discriminant analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXBoXp06a2HX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUNIz1zoa0Kq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}